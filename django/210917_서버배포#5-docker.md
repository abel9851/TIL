# 서버배포 #5 - docker

- ## dockerfile 만들기

dockerfile은 개발환경에서 만들자.  

우선 python 3.9.1을 받아야할듯 

도커에서 포트 80:80의 의미는,  
앞의 80은 인스턴스, 뒤의 80은 컨테이너를 뜻한다.  
즉, 호스트(인스턴스) 80번포트와 컨테이너 80번 포트를 연결한다는 것으로  
클라이언트가 example.com:80으로 접근하면  
example.com:80의 80은 호스트(인스턴스)의 80이다.  
그 80번 포트는 컨테이너 80번포트로 연결되어 있기때문에  
요청은 80번 포트를 사용하는 컨테이너로 가게 된다.  
즉 클라이언트의 80번포트요청 -> 호스트(인스턴스)의 포트가 80번이 열려있으면 그 80번포트로 요청을 받음  
-> 호스트(인스턴스)의 80번 포트는  특정 컨테이너의 80번포트와 연결되어 있으니  
컨테이너에 요청이 전달된다.  
이렇게 연결된 포트로 신호를 전달하는 것을  
**포트 포워딩(port forwarding)이라고 한다**  

- ## 장고 컨테이너 만들기  
    1. 깃허브에 소스 업로드 하기  
   서버에, 도커를 이용하여 장고 컨테이너를 만드려면  
   우선 깃허브에 소스코드를 올려야한다.  

   이 작업에서 아주 중요한 작업이 있는데  
   현재 장고 프로젝트는 가상환경인 pipenv에서 여러가지 패키지를 설치하고 만든 상태이다.  
   (django-environ, django-dotenv 등은 따로 환경변수를 .env 파일을 통해 관리하기 위해 설치한 것이다.)  
   (django-environ, django-dotenv 둘 중 하나만 있어도 된다.)  

   서버에서도 같은 패키지를 설치해줘야 움직임으로 패키지, 라이브러리 리스트를 만들어야한다.  
   `pipenv run pip freeze > requirements.txt`를 사용해서 requirements.txt를 만들고  
   이를 깃허브에 올리자.  
   requirements.txt 파일 하나로도 같은 가상환경을 구축할 수 있다.  
   ]그리고 도커의 컨테이너는 하나의 격리된 공간이기 때문에  
   굳이 pipenv를 설치해서 가상환경을 구축해줄 필요가 없을 듯 하다.  
   **pipenv run pip freeze requirements.txt를 하기 전에 gunicorn을 먼저 pipenv install gunicorn을 해주고 하도록 하자**  


        의문점:
        현재 장고프로젝트에서 gulp은 tailwindcss와, scss->css 변환을 위해 설치했던 상태인데  
        이를 배포환경에서도 설치할 필요가있나?(package.json)
        
        무엇보다 npm run css로 gulp을 통해 설치했던 tailwindcss로
        작성했던 scss파일은, css로 변환되어 따로 파일에 저장되어 있는 상태이다  
        그러니까 즉, css가 앱에 적응되어 있는 상태에서 소스코드를 올리는 것인데  
        굳이 배포환경에서 gulp, gulpfile, package.json에 있는 패키지들을 설치할 필요가 있을까? 
        
        찾아보고 결정하자.  

    2. 도커 파일 명령어 
    FROM: 베이스 이미지를 골라주는 커맨드(이미지를 상속받는 느낌)  
    RUN: 커맨드를 실행시켜주는 커맨드  
    예를 들어 파이썬이 구동되는 환경을 조성했다고 하면  
    거기서 필요한, pip list, pip install, git clone 등의 명령어를 컨테이너에서 실행시킬 수 있는 명령어가  
    RUN이다.  
    WORKDIR: cd Documents 에서 쓰는 cd와 비슷하다.  
    폴더 안에 들어가는 명령어다.  
    차이점은 cd는 상대경로이지만, WORKDIR는 절대경로다.  
    EXPOSE: 포트를 사용할 수 있도록 노출시키는 명령어다.  
    CMD: 필요한 커맨드, 항상 컨테이너가 실행될때마다 필요한 커맨드를 적는 명령어다.  
    예를 들자면 pipenv shell, python manage.py runserver 등

    3. 도커 파일 작성  
전제는 FROM 명령어로 이미지를 가지고 왔을 때부터의 순서  
            os version match
            install required programs
            install python
            install library
            set env PATH
            deploy Test
    

우선 로컬에서 도커파일을 작성할 경우,  
앱이 있는 곳에서 Dockerfile이라는 이름의 파일을 만든다.  

CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]의 python manage.py runserver를 대신하는 건  
gunicorn으로 한다.  


```python

# starscope/dockerfile

FROM python:3.9.1

WORKDIR /home/

RUN git clone https://github.com/abel9851/starscope.git

WORKDIR /home/starscope

# 이 부분에서 일단 문제가 있을수도 있다.
# 개발환경에서는 pipenv를 설치한 후, 거기에 장고를 비롯한 라이브러리들을 설치했기 때문이다.
# 아래의 커맨드는 개발환경에서 설치했던 라이브러리들을 가상환경(pipenv)없이 설치하겠다는 뜻이다.
# -r은 pip의 옵션 명령어로, 주어진 요구 사항 파일에서 설치한다, 이 옵션은 여러 번 사용할 수 있다라는 뜻이다.
RUN pip install -r requirements.txt

# 개발환경과는 다르게 터미널없이 그냥
# RUN이라는 명령어를 사용해서 migrate를 할 수 있다는게 인상적이다.
# migrate는 DB와 연동시켜주는 작업이다.
RUN python manage.py migrate



```

4. 도커 네트워크(Nginx 설정 변경)  

참조:  
[도커 네트워크 구성](https://real-dongsoo7.tistory.com/129)  
[도커 네트워크 생성 1](https://blog.d0ngd0nge.xyz/docker-network/)  
[도커 네트워크 생성 2](https://wooono.tistory.com/9)  


Nginx 컨테이너와 장고 컨테이너(guncorn도 설치된), 두개의 컨테이너가 연결이 되도록 하자.  


Nginx는 설치가 되면, 그 설치된 컴퓨터(혹은 컨테이너)의 포트 80번을 nginx를 호출하도록 자동으로 설정한다.  
즉, Nginx를 컨테이너로 만들면, 그 컨테이너(실행환경)의 80번 포트는 nginx와 연결되어 있는 상태다.  
그 컨테이너를 만들때 컨테이너의 80번 포트와 외부 80번포트, 즉 호스트의 80번 포트를 80:80으로 바인드를 하면  
클라이언트에서 요청이 오게 되면 nginx가 실행된다.  

문제는 nginx컨테이너에서 장고 컨테이너로는 킆라이언트에서  
서버로 요청할때와는 달리, ip와 도메인 등이 없는 상태이다.  

이것을 해결해주는 도구가 바로 도커 네트워크다.  
컨테이너를 여러개 만들때 그 컨테이너를 하나의 네트워크로 묶어주는게 도커 네트워크다.  

작동방식은 도커 안에다가 새로운 네트워크를 만든다.  
이 네트워크 안에 있는 컨테이너끼리는 컨테이너네임(Container Name)을 기반으로 해서 서로 요청을 주고 받을 수 있게 할 수 있다.  

네트워크 안에서는 이 컨테이너네임 자체가 도메인처럼 작동하는 것이다.  

아래와 같이 네트워크에서 작성을 하면 인식을 해서  
해당 컨테이너에 요청을 넘길 수 있다.  

**즉, 장고 컨테이너는 외부포트랑 연결시켜 줄 필요가 없다.**  
**80:8000 등을 안해도 된다는 얘기다.** 

```
# django_container_gunicorn는 컨테이너네임이다.

http://django_container_gunicorn:8000

```


```
# 도커 네트워크 nginx-django를 만들어주자
# -d는 driver로 bridge방식으로 하고, 그 다음에 네트워크 이름이다.

docker network create -d=bridge nginx-django

# 네트워크를 생성했다면, 그 네트워크에 컨테이너를 연결시킨다.
# 컨테이너를 생성할때 같이 명령어로 지정해주거나
# 컨테이너 생성 후, 네트워크를 연결해주자. 

```

**장고 컨테이너를 생성할 때에는 반드시 만들어 놓은 도커 네트워크랑 연결해주자**  
**이는 nginx 컨테이너를 생성할 때에도 마찬가지이다.**  

5. nginx 설정
   
- 5-1. nginx.conf 설정

같은 도커 네트워크 내에서는 컨테이너네임으로 요청을 건네줄 수 있다.  
그러기 위해서는 도커 네트워크 연결 말고도 nginx의 설정을 변경해줘야한다.  
nginx.conf라는 파일을 만들고 아래의 코드를 작성한다.  

nginx.conf를 가상서버에 올려야하는데  
파일질라라는 소프트웨어를 사용해서 올린다.  



```
# nginx.conf

worker_processes auto;

events {

}

http {

  server {
    listen 80;


    location / {
        proxy_pass http://[컨테이너이름]:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
  }
}
```


**이 파일을, nginx 컨테이너를 만들때, volume을 연결해주자.**  
왜냐하면 컨테이너안은 격리된 공간이기 때문에  
host(ec2)에 설치한 nginx.conf를 읽으려면  
컨테이너 안에 그 파일을 이동시키는게 편하기 때문이다.  

```
container /etc/nginx/nginx.conf

host /home/django_course/nginx.conf


```



참조:  
[AWS로 장고 프로젝트 배포하기 - nginx, S3 연결](https://yeojin-dev.github.io/blog/aws-django-intermediate-6/)  
[docker nginx 설정](https://frontmulti.tistory.com/69)  
[nginx conf 설정](https://nerogarret.tistory.com/48)  
[nginx conf 설정-aws s3(일본어) 반드시 읽어보기](https://dev.classmethod.jp/articles/private-content-hosting-with-nginx/)  
[nginx conf 설정-aws s3](https://koty.hatenablog.com/entry/2018/12/09/094339)  
[aws s3 커스텀 도메인에 대해](https://velog.io/@hyeseong-dev/MySQL-S3-%EC%82%AC%EC%9A%A9-Storage%EC%84%9C%EB%B2%84-%EC%97%B0%EB%8F%99)  
[aws s3 경로에 대해](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/VirtualHosting.html)  
[Gunicorn nignx 기본설정링크](https://gunicorn.org/deployment)  
[Filezilla 프로그램링크](https://filezilla-project.org/)  
[리눅스 bash,sh 의미](https://ithub.tistory.com/205)  
[도커 스택, 스웜, 컴포즈 차이점](https://log-laboratory.tistory.com/191)  
[도커, 컴포즈, 스웜, 쿠버네티스](https://devbull.xyz/docker-compose-swarm-kubernetes/)  
[데이터베이스 502에러](https://uhou.tistory.com/130)  
 

- 5-2. STATIC 파일 설정
클라이언트로부터 정적파일의 요청이 오면 그것을 서빙하는 것은 웹서버 즉, nginx의 일이다.  
하지만 개발환경에서 만든 장고 애플리케이션의 정적파일들(css, html, javascript)은 따로 장고 앱의 static 폴더에 있는 상황이다.  
게다가 AWS S3까지 사용해야한다.  

이런 상황에서 nginx가 static 파일을 사용하려면,  
장고 내부에 있는 정적파일들을 모아서(python manage.py collectstatic、취합)  
AWS S3에 올려야하고(장고의 settings.py에서 설정)  
AWS S3에 올려있는 정적파일들을 nignx와 싱크로(동기화)시켜야한다.  
(aws s3를 안썼다면 도커 안에서 Named Volume을 생성해서   
nginx, django 컨테이너들과 동기화를 시켰을 것이다.)  

6. 도커 스웜 모드

nginx.conf를 복사해놓은  
home/django_course에서 docker swarm init을 해주자.  
초기화를 해주면 current node is now a manager라는 메시지가 뜨는데  
노드에서도 매니저 노드랑 일반 노드로 나뉜다.  

관리자 노드는 시스템 설정을 만질수 있다.  

그러면 노드에 시크릿, 스웜, 서비스, config 등이 생성된다.  

스웜모드가 켜졌으니까  
설정파일을 만들어줘야한다.  
docker-compose.yml이라는 파일을 로컬환경 앱에 만들어주자.  

stack에서 docker-compose.yml을 실행

도커 시크릿에서 보안관련파일(.env)을 다루게해서 보안관련파일이 필요한 서비스에게  
보안파일을 제공하도록 해놓는다.  

도커 스웜 모드의 docker-compose.yml에서는 build, restart명령어를 지원하지 않는다.  


7. 끝난 후에 컨테이너 접속 & 슈퍼유저 생성
컨테이너에 접속하려면  
`docker exec -it [134adb2ba12 혹은 my-container] /bin/bash`를 입력하면 된다.  
나갈 때는 `exit`를 타이핑하면 된다.  

참조:  
[도커 컨테이너 접속 #1](https://itholic.github.io/docker-enter-container/)  
[도커 컨테이너 접속 #2](https://bluese05.tistory.com/21)  
