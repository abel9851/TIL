# 서버에 배포하기(AWS 사용)

탄력적 IP를 사용해서 EC2 인스턴스에 연결한 상태다.

- ## EC2(우분투)를 SSH에 접속

윈도우10에서는 SSH 클라이언트를 설치한 후,  
SSH 서버를 추가 기능으로 설치해준다. 

SSH(Secure SHell)은 네트워크 상의 다른 컴퓨터에 로그인하거나  
원격 시스템에서 명령을 실행하고 다른 시스템으로 파일을 복사할 수 있도록 해주는  
응용 프로그램 또는 그 프로토콜을 가르킨다. 

그다음 Windows Powershell을 관리자 권한으로 실행시켜서  
`Start-Service sshd`를 해서 상태를 Running으로 바꾼다.  
SSH를 사용할 수 있도록 설정을 바꿔주는 것이다.  

그리고 나서는 AWS EC2에 접속하면 되는데 이때 터미널은  
Windows PowerShell, 윈도우의 cmd, git bash등, 아무거나 사용해도 상관없다.  
들어갔으면, 필요한 것은 서버 컴퓨터의 ID(유저네임), IP, 키(pem)이다.  
다운 받은 pem파일은 읽기전용으로 해주자.  
어쩌다가 에러가 났을 경우, pem파일에 권한이 많이 주어져 있어서 에러가 나는 경우도 있다고 한다.  
이때는 구글링을 해서 찾아보자.
키가 있는 곳에서 키를 써주거나, 키가 있는 경로를 써주면 접속이 가능하다.

ubuntu의 경우, id는 무조건 ubuntu이다.
-i는 명령어로, RSA인증을 위한 비밀키를 읽어 올 아이덴티티 파일을 선택하는 것이다.  

참조:
[EC2 - SSH로 접속](https://5equal0.tistory.com/entry/AWS-EC2-%EC%9D%B8%EC%8A%A4%ED%84%B4%EC%8A%A4%EC%97%90-ssh-%EC%A0%91%EC%86%8D-%ED%95%98%EA%B8%B0)  
[SSH 기본소개](https://velog.io/@hyeseong-dev/%EB%A6%AC%EB%88%85%EC%8A%A4-ssh%EB%9E%80)  
[SSH 명령어 사용법 #1](https://wlsvud84.tistory.com/12)  
[SSH 명령어 사용법 #2](https://experiences.tistory.com/33)  
[RSA 암호화](https://cnu-cse-15-jh.tistory.com/1)  
[우분투 기본 설정](https://nachwon.github.io/django-deploy-1-aws/)

```

ssh -i keypair.pem ubuntu@ip

```
- ## EC2에 docker 설치

1. 아래의 코드를 터미널에 입력  

`sudo apt-get update`는 리눅스에 있는 패키지들을 업데이트해주는 명령어다.  

```
# 리눅스에 있는 패키지들을 업데이트
 sudo apt-get update

 # 필요한 라이브러리들을 설치
 sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg \
    lsb-release

```

2. 도커의 오피셜 GPG key를 추가

```
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
```

3. stable 레포짓토리 설정

```
 echo \
  "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
```

4. 도커 엔진 설치

실질적으로 설치하는 명령어는 `sudo apt-get install docker-ce docker-ce-cli containerd.io`인데  
안될 수도 있다.  
현재 사용하는 우분투가 20.04인데 아직 지원을 안하는 것 같다.  
이럴때는 `sudo apt-get install -y docker.io`로 설치한 뒤,  
`docker -v`로 체크해보자.  

참조:[스택오버플로우 - 도커 설치 문제](https://stackoverflow.com/questions/61401626/docker-installation-failed-on-ubuntu-20-04-ltsvmware)

```
 sudo apt-get update
 sudo apt-get install docker-ce docker-ce-cli containerd.io
```

5. Docker 버전확인과 Dokcer 실행권한 주기

권한주기: `sudo usermod -aG docker $USER`
버전확인: `docker -v`




참조:
[우분투 sudo에 대해](https://webdir.tistory.com/255)  
[docker 공식문서 - 우분투에 설치](https://docs.docker.com/engine/install/ubuntu/)  
[docker, pipenv](https://kawasin73.hatenablog.com/entry/2019/09/22/220901)  
[pipenv와 docker 그리고 배포](https://cocook.tistory.com/139)



서버 안에 pipenv을 설치해야 모듈에러가 나지 않는다. 

여기서 쓸 수 있는 방법은 pip을 이용하는 것이다.  
pip은 패키지들을 설치하는 가장 기본적인 방법이다.  

원래 개발환경에서 설치할떄도  
pip(파이썬을 설치하면 자동으로 따라온다)을 통해 pipenv을 설치했고,  
설명하자면, pipenv을 pip으로 전역으로 설치한 후  
원하는 폴더에 가서, pipenv으로 python3을 설치(버블 안에 파이썬을 설치한다)  
그 다음 pipenv shell로 버블 안에 들아가서 pipenv install django로 장고를 설치하고 그랬다.  
django와 pipenv의 설치순서가 해깔리면  
영상을 다시 보자.  

EB에서 배포를 하고 나면, 모듈에러라고해서  
모듈을 인식못하는 에러가 나오는데  
이는 pipenv가 설치되어있지 않기 때문이다.  
그러므로 pip freeze > requirements.txt 로 현재 설치된 파일들의 리스트를 뽑자.  


혹은 pipenv install pipenv-to-requirements을 사용해서  
pipenv-to-requirements 모듈을 설치한 뒤,  
pipenv-to-requirements -f 로  
requirements.txt를 만들어도 상관없다.  
(근데 전부다 목록이 나오는게 아닌 것 같은데 시험해봐야할것 같다.)  

requirements.txt는 기본값이다.  
package.json과 비슷한.  
파이썬 프로젝트가 있다면 반드시 requirements.txt가 있어야한다.  

requirements.txt(내용의 마지막줄이 빈칸이여야 작동한다)가 생겼다면 git add를 해서  
git에 올리자.  

**pipenv lock -r > requirements.txt**


- 데이터베이스 설정  
RDS에서는 어떻게 하나??  

장고공식문서에 다른 데이터베이스를 사용하는 방법이 나와있다.  
PostgreSQL을 사용하려면 PostgreSQL의 어댑터인 psycopg2를 requirements.txt에 써줘야한다.  
`psycopg==2.8.4`  
**psycopg를 설치하려면 우선 PostgreSQL 소프트웨어가 서버에 설치되어 있어야한다.**  

아래와 같이 쓰면, 깃에 올릴때 코드가 다 노출되기 때문에  
데이터베이스에 관한 정보는 환경변수처럼 다룰 것이다.  

**.env은 manage.py runsever를 했을때 로드된다.**  
wsgi를 호출하는 방식으로는 .env는 로드되지 않는다.  

**엘라스틱 빈스톡에서 환경변수 설정은  소프트웨어파트에서 수동으로 가능하다.**  
EC2나 RDS에서도 방법이 있을 것이다.  

참고:[점프 투 장고 - 데이터베이스](https://wikidocs.net/75561)  

```python
# PostgreSQL 설정방법 


DATABASES = {
    "default": {
        "ENGINE": "django.db.backends.postgresql",
        # RDS 인스턴스의 엔드포인트라고 써져있는 정보를 기입하면 된다. 
        "HOST": 
        # AWS-RDS를 사용한다면, 그 인스턴스의 이름을 적자.
        "NAME": "postgres",
        "USER": "postgresql",
        # RDS 인스턴스를 만들때 설정했던 패스워드
        "PASSWORD": "",
        # 포트도 인스턴스 정보에 나와있다.
        "PORT": "5432",
    }
}


```

RDS의 환경변수를 사용할때

```python
# PostgreSQL 설정방법 


# RDS_HOST와 같은 변수명은 소프트웨어 파트에서 직접 설정 가능하다.  
DATABASES = {
    "default": {
        "ENGINE": "django.db.backends.postgresql",
        "HOST": os.environ.get("RDS_HOST"),
        "NAME": os.environ.get("RDS_NAME"),
        "USER": os.environ.get("RDS_USER"),
        "PASSWORD": os.environ.get("RDS_PASSWORD"),
        "PORT": "5432",
    }
}


```

- PostgreSQL 소프트웨어 설치  

장고에서AWS EB를 사용해서 배포할때) .extenstions/packages.config 라는 파일을 만들고  
아래와 같이 코드를 친다.  
자세한 설정방법과 내용은 AWS 공식문서에도 나와있다.  

설정이 다 끝났는데도 불구하고 무한로딩이 된다면  
RDS 데이터베이스에서 거부하고 있는 것이다. 이때 RDS의 시큐리티그룹에서  
장고를 받아들일수 있도록 설정해줘야한다.  EB 또한 EC2를 기반으로 하기 때문에  
RDS의 시큐리티 그룹이 EC2(EB)의 시큐리티 그룹을 허용하도록 설정을 변경해야한다.  


RDS의 인바운드 설정에서 유형을 All traffic으로 하고  
소스를 지정하면 그 소스에서 오는 모든 트래픽(http, PostgreSQL 등)을 허용한다는 뜻이다.  


```python

# .extenstions/01-packages.config
# dnldml 01-packages의 01은 실행순서다. AWS에서 01을 인식한다. 

packages:
    # yum은 리눅스에서의 pip같은 것이다.
    yum:
        # 96은 PostgreSQL의 버전인데 반드시 RDS로 쓰고 있는 버전을 써줘야한다.
        postgresql96-devel: []
        gettext-devel: []

```


```python

# .extenstions/02-django.config

container_commands:
    01_migrate:
      command: "django-admin.py migrate"
      # 한번더 영상을 보고 이해하도록하자
      leader_only: true
    02_compilemessages:
        command: "djangp-admin.py compilemessages"
    03_createsu:
        command: "djnago-admin createsu"
    04_collectstatic:
        command: "djnago-admin collectstatic --no-input"

option_settings:
    aws:elasticmeanstalk:container:python:
        WSGIPath: config/wsgi.py
    aws:elasticbeanstalk:application:environment:
    # 나의 경우에는 config.settings.prod 가 될 것이다. 
        DJNAGO SETRTINGS MODULE: config.settings


```


- ## Django


- 장고 ALLOWED_HOSTS

ALLOWED_HOSTS는 지정된 도메인에만  
나의 앱을 실행시킬 수 있게 하는 것이다.  

보안을 위해서 앱은 아무데서나 작동시키면 안된다.  
그러므로 ALLOWED_HOSTS 변수에 EC2 퍼블릭 IP를 적어주자.  

- S3 이용  

`pipenv install django-storages`
`pipenv install boto3`
dango-storages의 웹사이트를 보면 알겠지만  
이 모듈은 Amazon S3를 포함해서 여러 곳에 파일을 업로드하도록 허용해준다.  

설치후에는 settings.py의 INSTALLED_APPS에 django-storages를 추가해줘야한다.  

그리고 settings.py에서
`DEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'`와  
`STATICFILES_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'`를 적어줘야한다.  

아래의 설정이 끝났으면 개발환경에서 python.manage.py collectstatic을 해주자.  

```python

# settings.py

DEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'
STATICFILES_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'
AWS_ACCESS_KEY_ID = os.senviron.get("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.senviron.get("AWS_SECRET_ACCESS_KEY")
AWS_STORAGE_BUCKET_NAME = ""
AWS_AUTO_CREATE_BUCKET = True
# 이 설정에 대해서는 찾아서 확인해보자.
AWS_BUCKET_ACL = "public-read"

```

```python

# settings.py

AWS_S3_CUSTOM_DOMAIN =f"{AWS_STORAGE_BUCKET_NAME}.s3.amazonaws.com"
STATIC_URL = f"https://{AWS_S3_CUSTOM_DOMAIN}/static"

```